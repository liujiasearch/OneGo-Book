---
description: >-
  指南的目的是为了帮助想利用反向传播自己计算神经网络梯度的人，文章里不对算法做过多解释，而是直观地帮助读者知道如何使用该算法，希望读过这篇文章后，读者能自行计算任何形状的神经网络梯度。
---

# 反向传播算法指南

## 规范

神经网络由于结构复杂，如果不规范命名，往往搞不清楚公式中的符号到底指代网络中的哪部分。 一般我们将神经网络画成：

![](.gitbook/assets/sin%20%285%29.svg)

其中，把神经元按层分组，上图从左至右依次是第一层，第二层神经元组。而信号线也是从左至右称作第一组参数，第二组参数，以此类推。 第 n 层的神经元组的输入就是 n 组参数，输出就是n+1 组参数。 本文将给出反向梯度通用算法的说明。

## 正文

大部分的书籍会把单个神经元描述成如下形式：

$$
Y_i=\sigma(\sum{A_ix_i+b_i})
$$

用矩阵来描述由多个这样的神经元组成的一层神经元组是这样子的（一层指竖着的一排）：

$$
Y=\sigma(A*X+B)
$$

神经网络的形状如下图:

![](.gitbook/assets/sin%20%283%29.svg)

以最右边的输出层为例解释上面那个公式。其中 Y 是 2\*1 矩阵，对应神经元组输出， A 是 3\*2 矩阵，对应输入权重， X 是 3\*1 矩阵，表示输入， B是 2\*1 矩阵，表示神经元的偏置。我们如果使用这个的数学模型来考虑问题，面对反向传播时，我们需要把 A\*X 和 B 割裂开来处理，因为他们数学形式是不同的。为了思维的一致性，我们可以调整一下神经网络的结构，使得我们可以使用如下的式子来表示前面的式子：

$$
Y=\sigma(A*X)
$$

